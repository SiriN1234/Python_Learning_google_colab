{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chapter_8_1.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPEWCXtjreJhUbAqNoXYiWj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SiriN1234/Python_Learning_google_colab/blob/main/chapter_8_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 합성곱 신경망\n",
        "\n",
        "- 로지스틱 회귀 (일반 ML 모형) : 81% / 1950년대\n",
        "- 인공신경망 (딥러닝 초기 모형) : 87% / 1940~80년대\n",
        "- 합성곱(Convolution, CNN)\n",
        "  + 코드보다는 주요 용어 정리에 주력\n",
        "  + 발전사 : alexnet (2012) -> resnet -> efficientnet\n",
        "  + 채널, 이미지의 너비, 크기 (파라미터 튜닝)\n",
        "  + Vision Transformer\n",
        "- 비디오\n",
        "  + 객체인식(Object Detection)\n",
        "  + Yolo 논문\n",
        "- RNN / LSTM (자연어 처리)\n",
        "  + 구글에서 2017년에 Transformer 논문 발표"
      ],
      "metadata": {
        "id": "82sPuElFQ1YW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 합성곱의 장점\n",
        "\n",
        "- 기존 : 1차원 배열에서만 연산이 가능\n",
        "- 2차원 배열에도 연산을 할 수 있도록 구현\n",
        "  + 선형대수를 공부해야 함\n"
      ],
      "metadata": {
        "id": "aFwXpf6xc3gB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "keras.layers.Conv2D(10, kernel_size = (3, 3), activation = 'relu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuc5KcuFQ3V-",
        "outputId": "742e75c3-deab-4a96-f494-dab015285fb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.convolutional.Conv2D at 0x7fbe29416850>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 패딩의 목적\n",
        "\n",
        "- 배열의 크기를 조정하더라도 이미지 원 특성이 손실되는 것을 방지하는 것"
      ],
      "metadata": {
        "id": "ZXi_D2pIho95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.layers.Conv2D(10, kernel_size = (3, 3),\n",
        "                    activation = 'relu',\n",
        "                    padding = 'same',\n",
        "                    strides = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXwuV-5bhzuJ",
        "outputId": "ec4f0909-77e8-4e7b-fdc0-b23601d89f94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.convolutional.Conv2D at 0x7fbda5a1ffd0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 풀링\n",
        "\n",
        "- 값을 추출\n",
        "- 100 x 100 이미지 --> (수치로) 주요 이미지의 특성만 뽑은 후, 원 이미지와 같게 만듦 (50 x 50)"
      ],
      "metadata": {
        "id": "922ygsIfi9J7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 교재 437p\n",
        "- 1단계 : 이미지 데이터 입력\n",
        "- 2단계 : 합성곱 층\n",
        "  + (1) kernel_size + padding\n",
        "  + (2) 활성화 함수 적용\n",
        "  + (3) 각각의 특성맵을 산출\n",
        "- 3단계 : 풀링층\n",
        "  + (1) Max Pooling : 최댓값 추출\n",
        "  + (2) 최종 특성맵 만듦\n",
        "- 위 과정을 계속 만복하는 것이 CNN 알고리즘\n",
        "\n",
        "#### 알고리즘\n",
        "\n",
        "- 4단계 : 밀집층 (Fully Connected Layer)\n",
        "  + Chapter 7장에서 이미 배움\n",
        "- 5단계 : 분류 예측값을 산출 (Softmax 활성화 함수)\n",
        "\n",
        "#### 주요 키워드 : 사전학습(Pretrained) / 전이학습(Transfer Learning) / 파인 튜닝(Fine Tuning)\n",
        "\n",
        "- 캐글 경진대회\n",
        "- 클래스 공부 필수"
      ],
      "metadata": {
        "id": "hHUCxxzfnYh7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 키워드로 끝내는 핵심 포인트\n",
        "\n",
        "- **합성곱**은 밀집층과 비슷하게 입력과 가중치를 곱하고 절편을 더하는 선형 계산입니다. 하지만 밀집층과 달리 각 합성곱은 입력 전체가 아니라 일부만 사용하여 선형 계산을 수행합니다.\n",
        "- 합성곱 층의 **필터**는 밀집층의 뉴런에 해당합니다. 필터의 가중치와 절편을 종종 커널이라고 부릅니다. 자주 사용되는 커널의 크기는 (3, 3) 또는 (5, 5)입니다. 커널의 깊이는 입력의 깊이와 같습니다\n",
        "- **특성 맵**은 합성곱 층이나 풀링 층의 출력 배열을 의미합니다. 필터 하나가 하나의 특성 맵을 만듭니다. 합성곱 층에서 5개의 필터를 적용하면 5개의 특성 맵이 만들어집니다.\n",
        "- **패딩**은 합성곱 층의 입력 주위에 추가한 0으로 채워진 픽셀입니다. 패딩을 사용하지 않는 것을 밸리드 패딩이라고 합니다. 합성곱 층의 출력 크기를 입력과 동일하게 만들기 위해 입력에 패딩을 추가하는 것을 세임 패딩이라고 합니다.\n",
        "- **스트라이드**는 합성곱 층에서 필터가 입력 위를 이동하는 크기입니다. 일반적으로 스트라이드는 1픽셀을 사용합니다.\n",
        "- **풀링**은 가중치가 없고 특성 맵의 가로세로 크기를 줄이는 역할을 수행합니다. 대표적으로 최대 풀링과 평균 풀링이 있으며 (2, 2) 풀링으로 입력을 절반으로 줄입니다."
      ],
      "metadata": {
        "id": "nHhgz3NyuZWc"
      }
    }
  ]
}